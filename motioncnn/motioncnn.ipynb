{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MotionCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\present\\Github\\waymo-motion-prediction\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\present\\Github\\waymo-motion-prediction\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from abc import ABC\n",
    "from glob import glob\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import multiprocessing\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = 8\n",
    "\n",
    "PATH_DATASET = '../dataset/'\n",
    "PATH_TRAINING_DATASET = PATH_DATASET + 'training/'\n",
    "PATH_TESTING_DATASET = PATH_DATASET + 'testing/'\n",
    "PATH_VALIDATION_DATASET = PATH_DATASET + 'validation/'\n",
    "\n",
    "PATH_PREPROCESSED_DATASET = './preprocessed/'\n",
    "PATH_PREPROCESSED_TRAINING_DATASET = PATH_PREPROCESSED_DATASET + 'training/'\n",
    "PATH_PREPROCESSED_TESTING_DATASET = PATH_PREPROCESSED_DATASET + 'testing/'\n",
    "PATH_PREPROCESSED_VALIDATION_DATASET = PATH_PREPROCESSED_DATASET + 'validation/'\n",
    "\n",
    "PATH_CHECKPOINTS = './checkpoints/'\n",
    "\n",
    "CONFIG_PREPROCESSING = {\n",
    "\t'raster_size': 512,\n",
    "\t'scale': 3,\n",
    "\t'roadgraph_distillation_rate': 5,\n",
    "\t'center_x': 256,\n",
    "\t'center_y': 256,\n",
    "}\n",
    "\n",
    "CONFIG_MODEL = {\n",
    "\t'backbone': 'resnet34',\n",
    "\t'n_modes': 3,\n",
    "\t'n_timestamps': 80,\n",
    "\t'predict_covariances': True,\n",
    "}\n",
    "\n",
    "CONFIG_TRAINING = {\n",
    "\t'num_epochs': 5,\n",
    "\t'eval_every': 10000,\n",
    "\t'optimizer': {\n",
    "\t\t'lr': 0.0003\n",
    "\t},\n",
    "\t'train_dataloader': {\n",
    "\t\t'batch_size': 16,\n",
    "\t\t'num_workers': 8,\n",
    "\t\t'shuffle': True\n",
    "\t},\n",
    "\t'val_dataloader': {\n",
    "\t\t'batch_size': 16,\n",
    "\t\t'num_workers': 8,\n",
    "\t\t'shuffle': False\n",
    "\t},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot_matrix(angle):\n",
    "  return np.array([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_rotate(x, shift, angle):\n",
    "\tassert isinstance(angle, (np.float32, np.float16, float))\n",
    "\tassert shift.shape[-1] == 2\n",
    "\tassert x.shape[-1] == 2\n",
    "\treturn (x + shift) @ rot_matrix(angle).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_shift(x, shift, angle):\n",
    "\tassert isinstance(angle, (np.float32, np.float16, float))\n",
    "\tassert shift.shape[-1] == 2\n",
    "\tassert x.shape[-1] == 2\n",
    "\treturn (x) @ rot_matrix(angle).T + shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filename(data_dict):\n",
    "\treturn str(data_dict['agent_id']) + '.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_if_not_exists(path):\n",
    "\tif not os.path.exists(path):\n",
    "\t\tos.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_saving_paths(path, data_dict):\n",
    "\tscenario_folder = os.path.join(path, data_dict['scenario_id'])\n",
    "\tagent_data_folder = os.path.join(scenario_folder, 'agent_data')\n",
    "\troadgraph_data_folder = os.path.join(scenario_folder, 'roadgraph_data')\n",
    "\tcreate_folder_if_not_exists(scenario_folder)\n",
    "\tcreate_folder_if_not_exists(agent_data_folder)\n",
    "\tcreate_folder_if_not_exists(roadgraph_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_roadgraph_data(path, data_dict, roadgraph_data):\n",
    "\tscenario_folder = os.path.join(path, data_dict['scenario_id'])\n",
    "\troadgraph_data_folder = os.path.join(scenario_folder, 'roadgraph_data')\n",
    "\tcreate_saving_paths(path, data_dict)\n",
    "\tnp.savez_compressed(os.path.join(roadgraph_data_folder, 'segments_global.npz'), **roadgraph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_agent_data(path, data_dict):\n",
    "\tscenario_folder = os.path.join(path, data_dict['scenario_id'])\n",
    "\tagent_data_folder = os.path.join(scenario_folder, 'agent_data')\n",
    "\tcreate_saving_paths(path, data_dict)\n",
    "\tnp.savez_compressed(os.path.join(agent_data_folder, generate_filename(data_dict)), **data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadgraphProcessor:\n",
    "\tdef __init__(self, data, config):\n",
    "\t\tself._config = config\n",
    "\t\tself._segments = None\n",
    "\t\tvalidity_flag = data['roadgraph_samples/valid'].numpy().flatten()\n",
    "\t\tself._roadgraph_xy = data['roadgraph_samples/xyz'].numpy()[validity_flag == 1][:, :2]\n",
    "\t\tself._roadgraph_type = data['roadgraph_samples/type'].numpy().flatten()[validity_flag == 1]\n",
    "\t\tself._ids = data['roadgraph_samples/id'].numpy().flatten()[validity_flag == 1]\n",
    "\n",
    "\tdef _get_splits(self):\n",
    "\t\tsplits = []\n",
    "\t\tprev_value = self._ids[0]\n",
    "\t\tfor i, idx in enumerate(self._ids):\n",
    "\t\t\tif idx != prev_value:\n",
    "\t\t\t\tsplits.append(i)\n",
    "\t\t\t\tprev_value = idx\n",
    "\t\tsplits.append(len(self._ids))\n",
    "\t\tsplits = [[splits[i - 1], splits[i]] for i in range(1, len(splits))]\n",
    "\t\treturn splits\n",
    "\n",
    "\tdef _get_color(self, segment_type):\n",
    "\t\ttype_to_color = {\n",
    "\t\t\t# 0:  (0, 0, 0, 0), # TODO: Include key 0\n",
    "\t\t\t1:  (0, 0, 0, 0),\n",
    "\t\t\t2:  (0, 0, 0, 255),\n",
    "\t\t\t3:  (0, 0, 255, 0),\n",
    "\t\t\t6:  (0, 0, 255, 255),\n",
    "\t\t\t7:  (0, 255, 0, 0),\n",
    "\t\t\t8:  (0, 255, 0, 255),\n",
    "\t\t\t9:  (0, 255, 255, 0),\n",
    "\t\t\t10: (0, 255, 255, 255),\n",
    "\t\t\t11: (255, 0, 0, 0),\n",
    "\t\t\t12: (255, 0, 0, 255),\n",
    "\t\t\t13: (255, 0, 255, 0),\n",
    "\t\t\t15: (255, 0, 255, 255),\n",
    "\t\t\t16: (255, 255, 0, 0),\n",
    "\t\t\t17: (255, 255, 0, 255),\n",
    "\t\t\t18: (255, 255, 255, 0),\n",
    "\t\t\t19: (255, 255, 255, 255)}\n",
    "\t\t\t# 20: (255, 255, 255, 255)} # TODO: Include key 20\n",
    "\t\treturn type_to_color[segment_type]\n",
    "\n",
    "\tdef _prepare_segments(self):\n",
    "\t\tgraph_segments = []\n",
    "\t\tgraph_types = []\n",
    "\t\tsplits = self._get_splits()\n",
    "\t\tfor (start, end) in splits:\n",
    "\t\t\tnum_points = max(int((end - start) / self._config['roadgraph_distillation_rate']), 2)\n",
    "\t\t\troadline_ids = self._ids[start:end]\n",
    "\t\t\troadline_types = self._roadgraph_type[start:end]\n",
    "\t\t\tassert all(roadline_ids == roadline_ids[0])\n",
    "\t\t\tif roadline_types[0] == 18:\n",
    "\t\t\t\tdistilled_roadline_data = self._roadgraph_xy[start:end]\n",
    "\t\t\telse:\n",
    "\t\t\t\tidx = np.linspace(start, end - 1, num_points).astype(int)\n",
    "\t\t\t\tdistilled_roadline_data = self._roadgraph_xy[idx]\n",
    "\t\t\tsegments = np.concatenate([\n",
    "\t\t\t\tnp.pad(distilled_roadline_data, ((0, 1), (0, 0)))[:, None, :],\n",
    "\t\t\t\tnp.pad(distilled_roadline_data, ((1, 0), (0, 0)))[:, None, :]],\n",
    "\t\t\t\taxis=1)[1:-1]\n",
    "\t\t\tgraph_segments.append(segments)\n",
    "\t\t\tgraph_types.extend([roadline_types[0]] * segments.shape[0])\n",
    "\t\tself._segments = np.concatenate(graph_segments, axis=0)\n",
    "\t\tself._segment_types = graph_types\n",
    "\n",
    "\tdef center_to(self, target_agent_xy, target_agent_yaw):\n",
    "\t\treturn shift_rotate(self._segments, -target_agent_xy, -target_agent_yaw)\n",
    "\n",
    "\tdef json(self):\n",
    "\t\treturn json.dumps(np.round(self._segments.tolist(), 2).tolist())\n",
    "\n",
    "\tdef __str__(self) -> str:\n",
    "\t\treturn self.json()\n",
    "\n",
    "\tdef render(self, target_agent_xy, target_agent_yaw):\n",
    "\t\tif self._segments is None:\n",
    "\t\t\tself._prepare_segments()\n",
    "\t\tsegments = self.center_to(target_agent_xy, target_agent_yaw)\n",
    "\t\tmasked_raster = np.zeros((self._config['raster_size'], self._config['raster_size'], 1), np.uint8)\n",
    "\t\ttyped_raster = np.zeros((self._config['raster_size'], self._config['raster_size'], 4), np.uint8)\n",
    "\t\tfor segment_type, segment in zip(self._segment_types, segments):\n",
    "\t\t\t# INFO: Added code to skip 0 and 20 segment types newly added to the dataset\n",
    "\t\t\tif segment_type == 0 or segment_type == 20:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tint_segment = (segment * self._config['scale'] + \\\n",
    "\t\t\t\tnp.array(\n",
    "\t\t\t\t\t[self._config['center_x'], self._config['center_y']])) \\\n",
    "\t\t\t\t\t.astype(int)\n",
    "\t\t\tmasked_raster = cv2.line(\n",
    "\t\t\t\tmasked_raster,\n",
    "\t\t\t\tint_segment[0], int_segment[1],\n",
    "\t\t\t\t255, 1)\n",
    "\t\t\ttyped_raster = cv2.line(\n",
    "\t\t\t\ttyped_raster,\n",
    "\t\t\t\tint_segment[0], int_segment[1],\n",
    "\t\t\t\tself._get_color(segment_type), 1)\n",
    "\t\traster = np.concatenate([masked_raster, typed_raster], axis=-1)\n",
    "\t\treturn raster\n",
    "\n",
    "\tdef get_roadgraph_segments_data(self):\n",
    "\t\treturn {'roadgraph_segments': self._segments}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentProcessor:\n",
    "\tdef __init__(self, data, config):\n",
    "\t\tself._config = config\n",
    "\n",
    "\t\thistory_valid = np.concatenate([\n",
    "      data['state/past/valid'].numpy(),\n",
    "      data['state/current/valid'].numpy()], axis=-1\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tpresent_in_history = np.max(history_valid, axis=-1)\n",
    "\t\tself._is_target = data['state/tracks_to_predict'].numpy().flatten()\n",
    "\t\tselector = np.logical_or(present_in_history == 1, self._is_target == 1)\n",
    "\n",
    "\t\tself._history_xy = np.concatenate([\n",
    "\t\t\tnp.concatenate([\n",
    "\t\t\t\tdata['state/past/x'].numpy(),\n",
    "\t\t\t\tdata['state/current/x'].numpy()], axis=-1)[:, :, None],\n",
    "\t\t\tnp.concatenate([\n",
    "\t\t\t\tdata['state/past/y'].numpy(),\n",
    "\t\t\t\tdata['state/current/y'].numpy()], axis=-1)[:, :, None]],\n",
    "\t\taxis = -1)[selector]\n",
    "\n",
    "\t\tself._history_yaw = np.concatenate([\n",
    "\t\t\tdata['state/past/bbox_yaw'].numpy(),\n",
    "\t\t\tdata['state/current/bbox_yaw'].numpy()],\n",
    "\t\taxis = -1)[selector]\n",
    "\n",
    "\t\tself._history_valid = np.concatenate([\n",
    "\t\t\tdata['state/past/valid'].numpy(),\n",
    "\t\t\tdata['state/current/valid'].numpy()],\n",
    "\t\taxis = -1)[selector]\n",
    "\n",
    "\t\tself._future_xy = np.concatenate([\n",
    "\t\t\tdata['state/future/x'].numpy()[:, :, None],\n",
    "\t\t\tdata['state/future/y'].numpy()[:, :, None]],\n",
    "\t\taxis = -1)[selector]\n",
    "\n",
    "\t\tself._future_valid = data['state/future/valid'].numpy()[selector]\n",
    "\n",
    "\t\tself._current_xy = np.concatenate([\n",
    "\t\t\tdata['state/current/x'].numpy(),\n",
    "\t\t\tdata['state/current/y'].numpy()], axis = -1)[selector]\n",
    "\n",
    "\t\tself._history_speed = data['state/past/speed'].numpy()[selector]\n",
    "\t\tself._current_speed = data['state/current/speed'].numpy().flatten()[selector]\n",
    "\t\tself._future_speed = data['state/future/speed'].numpy()[selector]\n",
    "\t\tself._current_yaw = data['state/current/bbox_yaw'].numpy().flatten()[selector]\n",
    "\t\tself._agents_id = data['state/id'].numpy().flatten().astype(int)[selector]\n",
    "\t\tself._is_sdc = data['state/is_sdc'].numpy().flatten().astype(int)[selector]\n",
    "\t\tself._scenario_id = data['scenario/id'].numpy().item().decode()\n",
    "\t\tself._agents_type = data['state/type'].numpy().flatten().astype(int)[selector]\n",
    "\t\tself._agents_width = data['state/current/width'].numpy().flatten()[selector]\n",
    "\t\tself._agents_length = data['state/current/length'].numpy().flatten()[selector]\n",
    "\n",
    "\tdef target_agents_idx(self):\n",
    "\t\treturn np.arange(len(self._is_target))[self._is_target == 1]\n",
    "\n",
    "\tdef get_target_agent_position(self, idx):\n",
    "\t\treturn self._current_xy[idx], self._current_yaw[idx]\n",
    "\t\n",
    "\tdef _gen_box(\n",
    "    self, current_agent_xy, current_agent_yaw,\n",
    "    target_agent_xy, target_agent_yaw,\n",
    "    current_agent_length, current_agent_width\n",
    "\t):\n",
    "\t\tbox = np.array([\n",
    "\t\t\t[-current_agent_length / 2, -current_agent_width / 2],\n",
    "\t\t\t[ current_agent_length / 2, -current_agent_width / 2],\n",
    "\t\t\t[ current_agent_length / 2,  current_agent_width / 2],\n",
    "\t\t\t[-current_agent_length / 2,  current_agent_width / 2]])[None, ]\n",
    "\t\tbox *= self._config['scale']\n",
    "\t\tbox = box @ rot_matrix(current_agent_yaw).T\n",
    "\t\tbox = shift_rotate(box, (current_agent_xy - target_agent_xy) * self._config['scale'], -target_agent_yaw)\n",
    "\t\treturn box\n",
    "\n",
    "\tdef _draw_box(\n",
    "\t\tself, raster,\n",
    "\t\tcurrent_agent_xy, current_agent_yaw,\n",
    "\t\ttarget_agent_xy, target_agent_yaw,\n",
    "\t\tcurrent_agent_length, current_agent_width\n",
    "\t):\n",
    "\t\traster = cv2.fillPoly(\n",
    "\t\t\traster, \n",
    "\t\t\t(self._gen_box(\n",
    "\t\t\t\tcurrent_agent_xy, current_agent_yaw,\n",
    "\t\t\t\ttarget_agent_xy, target_agent_yaw,\n",
    "\t\t\t\tcurrent_agent_length, current_agent_width) + \\\n",
    "\t\t\t\t\tnp.array([\n",
    "\t\t\t\t\t\tself._config['center_x'], self._config['center_y']])) \\\n",
    "\t\t\t\t\t\t.astype(int),\n",
    "\t\t\t128, lineType=cv2.LINE_AA)\n",
    "\t\traster = cv2.polylines(\n",
    "\t\t\traster, \n",
    "\t\t\t(self._gen_box(\n",
    "\t\t\t\tcurrent_agent_xy, current_agent_yaw,\n",
    "\t\t\t\ttarget_agent_xy, target_agent_yaw,\n",
    "\t\t\t\tcurrent_agent_length, current_agent_width) + \\\n",
    "\t\t\t\t\tnp.array([\n",
    "\t\t\t\t\t\tself._config['center_x'], self._config['center_y']])) \\\n",
    "\t\t\t\t\t\t.astype(int),\n",
    "\t\t\tTrue, 255, lineType=cv2.LINE_AA, thickness=1)\n",
    "\t\treturn raster\n",
    "\n",
    "\tdef render(self, target_agent_order_idx):\n",
    "\t\tagents_raster = [np.zeros((\n",
    "\t\t\tself._config['raster_size'], self._config['raster_size'], 1),\n",
    "\t\t\tnp.uint8) for _ in range(22)\n",
    "\t\t]\n",
    "\n",
    "\t\ttarget_agent_xy, target_agent_yaw = self.get_target_agent_position(target_agent_order_idx)\n",
    "\t\t\n",
    "\t\tfor rendering_agent_agent_order_idx, (\n",
    "\t\t\trendering_agent_history_xy,\n",
    "\t\t\trendering_agent_history_yaw,\n",
    "\t\t\trendering_agent_length,\n",
    "\t\t\trendering_agent_width,\n",
    "\t\t\trendering_agent_history_valid) in enumerate(zip(\n",
    "\t\t\t\tself._history_xy, self._history_yaw,\n",
    "\t\t\t\tself._agents_length, self._agents_width, self._history_valid)):\n",
    "\t\t\t\n",
    "\t\t\tfor history_timestamp, (\n",
    "\t\t\t\trendering_agent_history_xy_state,\n",
    "        rendering_agent_history_yaw_state,\n",
    "        rendering_agent_history_valid_state) in enumerate(zip(\n",
    "\t\t\t\t\trendering_agent_history_xy,\n",
    "\t\t\t\t\trendering_agent_history_yaw,\n",
    "\t\t\t\t\trendering_agent_history_valid)):\n",
    "\n",
    "\t\t\t\tif rendering_agent_history_valid_state == 0:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tchannel = history_timestamp\n",
    "\n",
    "\t\t\t\tif target_agent_order_idx == rendering_agent_agent_order_idx:\n",
    "\t\t\t\t\tchannel += 11\n",
    "\n",
    "\t\t\t\tagents_raster[channel] = self._draw_box(\n",
    "\t\t\t\t\tagents_raster[channel],\n",
    "\t\t\t\t\trendering_agent_history_xy_state,\n",
    "\t\t\t\t\trendering_agent_history_yaw_state,\n",
    "\t\t\t\t\ttarget_agent_xy, target_agent_yaw,\n",
    "\t\t\t\t\trendering_agent_length,\n",
    "\t\t\t\t\trendering_agent_width\n",
    "\t\t\t\t)\n",
    "\n",
    "\t\tagents_raster = np.concatenate(agents_raster, axis=-1)\n",
    "\t\treturn agents_raster\n",
    "\n",
    "\tdef get_numerical_data(self, agent_order_idx):\n",
    "\t\tagent_gt_global = self._future_xy[agent_order_idx]\n",
    "\t\ttarget_agent_shift, target_agent_yaw = \\\n",
    "\t\t\tself.get_target_agent_position(agent_order_idx)\n",
    "\t\tnumerical_data = {\n",
    "\t\t\t'agent_id': self._agents_id[agent_order_idx],\n",
    "\t\t\t'scenario_id': self._scenario_id,\n",
    "\t\t\t'is_sdc': self._is_sdc[agent_order_idx],\n",
    "\t\t\t'agent_type': self._agents_type[agent_order_idx],\n",
    "\t\t\t'future_global': agent_gt_global,\n",
    "\t\t\t'future_local': shift_rotate(agent_gt_global, -target_agent_shift, -target_agent_yaw),\n",
    "\t\t\t'future_valid': self._future_valid[agent_order_idx],\n",
    "\t\t\t'history_global': self._history_xy[agent_order_idx],\n",
    "\t\t\t'history_valid': self._history_valid[agent_order_idx],\n",
    "\t\t\t'history_yaw_global': self._history_yaw[agent_order_idx],\n",
    "\t\t\t'current_xy_global': self._current_xy[agent_order_idx],\n",
    "\t\t\t'history_speed': self._history_speed[agent_order_idx],\n",
    "\t\t\t'current_speed': self._current_speed[agent_order_idx],\n",
    "\t\t\t'future_speed': self._future_speed[agent_order_idx],\n",
    "\t\t\t'width': self._agents_width[agent_order_idx],\n",
    "\t\t\t'length': self._agents_length[agent_order_idx],\n",
    "\t\t\t'shift': target_agent_shift,\n",
    "\t\t\t'yaw': target_agent_yaw}\n",
    "\t\treturn numerical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_agent_features_by_timezone(timezone):\n",
    "\t_values_number_for_timezone = {\n",
    "    \"current\": 1,\n",
    "    \"future\": 80,\n",
    "    \"past\": 10\n",
    "\t}\n",
    "\n",
    "\tn_values = _values_number_for_timezone[timezone]\n",
    "\n",
    "\treturn {\n",
    "\t\tf\"state/{timezone}/x\": tf.io.FixedLenFeature(\n",
    "\t\t\t\t[128, n_values], tf.float32, default_value=None),\n",
    "\t\tf\"state/{timezone}/y\": tf.io.FixedLenFeature(\n",
    "\t\t\t\t[128, n_values], tf.float32, default_value=None),\n",
    "\t\tf\"state/{timezone}/z\": tf.io.FixedLenFeature(\n",
    "\t\t\t\t[128, n_values], tf.float32, default_value=None),\n",
    "\n",
    "\t\tf\"state/{timezone}/velocity_x\": tf.io.FixedLenFeature(\n",
    "\t\t\t\t[128, n_values], tf.float32, default_value=None),\n",
    "\t\tf\"state/{timezone}/velocity_y\": tf.io.FixedLenFeature(\n",
    "\t\t\t\t[128, n_values], tf.float32, default_value=None),\n",
    "\t\tf\"state/{timezone}/speed\": tf.io.FixedLenFeature(\n",
    "\t\t\t\t[128, n_values], tf.float32, default_value=None),\n",
    "\n",
    "\t\tf\"state/{timezone}/length\": tf.io.FixedLenFeature(\n",
    "\t\t\t\t[128, n_values], tf.float32, default_value=None),\n",
    "\t\tf\"state/{timezone}/width\": tf.io.FixedLenFeature(\n",
    "\t\t\t\t[128, n_values], tf.float32, default_value=None),\n",
    "\t\tf\"state/{timezone}/height\": tf.io.FixedLenFeature(\n",
    "\t\t\t\t[128, n_values], tf.float32, default_value=None),\n",
    "\n",
    "\t\tf\"state/{timezone}/bbox_yaw\": tf.io.FixedLenFeature(\n",
    "\t\t\t\t[128, n_values], tf.float32, default_value=None),\n",
    "\t\tf\"state/{timezone}/timestamp_micros\": tf.io.FixedLenFeature(\n",
    "\t\t\t\t[128, n_values], tf.int64, default_value=None),\n",
    "\t\tf\"state/{timezone}/valid\": tf.io.FixedLenFeature(\n",
    "\t\t\t\t[128, n_values], tf.int64, default_value=None),\n",
    "\t\tf\"state/{timezone}/vel_yaw\": tf.io.FixedLenFeature(\n",
    "\t\t\t\t[128, n_values], tf.float32, default_value=None)\n",
    "\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_description():\n",
    "\t_roadgraph_features = {\n",
    "    \"roadgraph_samples/dir\": tf.io.FixedLenFeature(\n",
    "        [30000, 3], tf.float32, default_value=None\n",
    "    ),\n",
    "    \"roadgraph_samples/id\": tf.io.FixedLenFeature(\n",
    "        [30000, 1], tf.int64, default_value=None\n",
    "    ),\n",
    "    \"roadgraph_samples/type\": tf.io.FixedLenFeature(\n",
    "        [30000, 1], tf.int64, default_value=None\n",
    "    ),\n",
    "    \"roadgraph_samples/valid\": tf.io.FixedLenFeature(\n",
    "        [30000, 1], tf.int64, default_value=None\n",
    "    ),\n",
    "    \"roadgraph_samples/xyz\": tf.io.FixedLenFeature(\n",
    "        [30000, 3], tf.float32, default_value=None\n",
    "    ),\n",
    "\t}\n",
    "\n",
    "\t_general_state_features = {\n",
    "    \"state/id\": tf.io.FixedLenFeature([128], tf.float32, default_value=None),\n",
    "    \"state/type\": tf.io.FixedLenFeature([128], tf.float32, default_value=None),\n",
    "    \"state/is_sdc\": tf.io.FixedLenFeature([128], tf.int64, default_value=None),\n",
    "    \"state/tracks_to_predict\": tf.io.FixedLenFeature(\n",
    "        [128], tf.int64, default_value=None),\n",
    "    \"scenario/id\": tf.io.FixedLenFeature([1], tf.string, default_value=None)\n",
    "\t}\n",
    "\n",
    "\t_traffic_light_features = {\n",
    "    \"traffic_light_state/current/state\":\n",
    "        tf.io.FixedLenFeature([1, 16], tf.int64, default_value=None),\n",
    "    \"traffic_light_state/current/valid\":\n",
    "        tf.io.FixedLenFeature([1, 16], tf.int64, default_value=None),\n",
    "    \"traffic_light_state/current/x\":\n",
    "        tf.io.FixedLenFeature([1, 16], tf.float32, default_value=None),\n",
    "    \"traffic_light_state/current/y\":\n",
    "        tf.io.FixedLenFeature([1, 16], tf.float32, default_value=None),\n",
    "    \"traffic_light_state/current/z\":\n",
    "        tf.io.FixedLenFeature([1, 16], tf.float32, default_value=None),\n",
    "    \"traffic_light_state/past/state\":\n",
    "        tf.io.FixedLenFeature([10, 16], tf.int64, default_value=None),\n",
    "    \"traffic_light_state/past/valid\":\n",
    "        tf.io.FixedLenFeature([10, 16], tf.int64, default_value=None),\n",
    "    \"traffic_light_state/past/x\":\n",
    "        tf.io.FixedLenFeature([10, 16], tf.float32, default_value=None),\n",
    "    \"traffic_light_state/past/y\":\n",
    "        tf.io.FixedLenFeature([10, 16], tf.float32, default_value=None),\n",
    "    \"traffic_light_state/past/z\":\n",
    "        tf.io.FixedLenFeature([10, 16], tf.float32, default_value=None),\n",
    "\t}\n",
    "\n",
    "\tfeatures_description = {}\n",
    "\tfeatures_description.update(_roadgraph_features)\n",
    "\tfeatures_description.update(_general_state_features)\n",
    "\tfeatures_description.update(_traffic_light_features)\n",
    "\n",
    "\tfor timezone in ['past', 'current', 'future']:\n",
    "\t\tfeatures_description.update(generate_agent_features_by_timezone(timezone))\n",
    "\n",
    "\treturn features_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prerender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prerender(data, config, output_path):\n",
    "\tdata = tf.io.parse_single_example(data, get_features_description())\n",
    "\n",
    "\tagent_processor = AgentProcessor(data, config)\n",
    "\troadgraph_processor = RoadgraphProcessor(data, config)\n",
    "\n",
    "\tfor i in agent_processor.target_agents_idx():\n",
    "\t\tagents_raster = agent_processor.render(i)\n",
    "\t\troadgraph_raster = roadgraph_processor.render(*agent_processor.get_target_agent_position(i))\n",
    "\t\tfull_raster = np.concatenate([roadgraph_raster, agents_raster], axis=-1)\n",
    "\n",
    "\t\tprepared_data = {'raster': full_raster}\n",
    "\t\tprepared_data.update(agent_processor.get_numerical_data(i))\n",
    "\n",
    "\t\tsave_agent_data(output_path, prepared_data)\n",
    "\t\t\n",
    "\tsave_roadgraph_data(output_path, prepared_data, roadgraph_processor.get_roadgraph_segments_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = [\n",
    "\tPATH_TRAINING_DATASET,\n",
    "\tPATH_TESTING_DATASET,\n",
    "\tPATH_VALIDATION_DATASET\n",
    "]\n",
    "\n",
    "path_preprocessed_dataset = [\n",
    "\tPATH_PREPROCESSED_TRAINING_DATASET,\n",
    "\tPATH_PREPROCESSED_TESTING_DATASET,\n",
    "\tPATH_PREPROCESSED_VALIDATION_DATASET\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for path in path_dataset:\n",
    "\tfiles = os.listdir(path)\n",
    "\tdatasets.append(tf.data.TFRecordDataset([os.path.join(path, f) for f in files]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUncomment to generate preprocessed data\\np = multiprocessing.Pool(N_JOBS)\\nprocesses = []\\n\\nfor i, dataset in enumerate(datasets):\\n\\tpath_output = path_preprocessed_dataset[i]\\n\\t\\n\\tfor data in tqdm(dataset.as_numpy_iterator()):\\n\\t\\tprocesses.append(\\n\\t\\t\\tp.apply_async(\\n\\t\\t\\t\\tprerender,\\n\\t\\t\\t\\tkwds = dict(\\n\\t\\t\\t\\t\\tdata = data,\\n\\t\\t\\t\\t\\tconfig = CONFIG_PREPROCESSING,\\n\\t\\t\\t\\t\\toutput_path = path_output\\n\\t\\t\\t\\t)\\n\\t\\t\\t)\\n\\t\\t)\\n\\t\\n\\tfor r in tqdm(processes):\\n\\t\\tr.get()\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Uncomment to generate preprocessed data\n",
    "p = multiprocessing.Pool(N_JOBS)\n",
    "processes = []\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "\tpath_output = path_preprocessed_dataset[i]\n",
    "\t\n",
    "\tfor data in tqdm(dataset.as_numpy_iterator()):\n",
    "\t\tprocesses.append(\n",
    "\t\t\tp.apply_async(\n",
    "\t\t\t\tprerender,\n",
    "\t\t\t\tkwds = dict(\n",
    "\t\t\t\t\tdata = data,\n",
    "\t\t\t\t\tconfig = CONFIG_PREPROCESSING,\n",
    "\t\t\t\t\toutput_path = path_output\n",
    "\t\t\t\t)\n",
    "\t\t\t)\n",
    "\t\t)\n",
    "\t\n",
    "\tfor r in tqdm(processes):\n",
    "\t\tr.get()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(ABC, nn.Module):\n",
    "\tdef _precision_matrix(shape, sigma_xx, sigma_yy):\n",
    "\t\tassert sigma_xx.shape[-1] == 1\n",
    "\t\tassert sigma_xx.shape == sigma_yy.shape\n",
    "\n",
    "\t\tbatch_size, n_modes, n_future_timstamps = sigma_xx.shape[0], sigma_xx.shape[1], sigma_xx.shape[2]\n",
    "\t\t\n",
    "\t\tsigma_xx_inv = 1 / sigma_xx\n",
    "\t\tsigma_yy_inv = 1 / sigma_yy\n",
    "\t\t\n",
    "\t\treturn torch.cat([\n",
    "\t\t\tsigma_xx_inv,\n",
    "\t\t\ttorch.zeros_like(sigma_xx_inv),\n",
    "\t\t\ttorch.zeros_like(sigma_yy_inv),\n",
    "\t\t\tsigma_yy_inv], dim=-1).reshape(batch_size, n_modes, n_future_timstamps, 2, 2)\n",
    "\n",
    "\tdef _log_N_conf(self, data_dict, prediction_dict):\n",
    "\t\tgt = data_dict['future_local'].unsqueeze(1)\n",
    "\n",
    "\t\tdiff = (prediction_dict['xy'] - gt) * data_dict['future_valid'][:, None, :, None]\n",
    "\t\tassert torch.isfinite(diff).all()\n",
    "\n",
    "\t\tprecision_matrices = self._precision_matrix(prediction_dict['sigma_xx'], prediction_dict['sigma_yy'])\n",
    "\t\tassert torch.isfinite(precision_matrices).all()\n",
    "\n",
    "\t\tlog_confidences = torch.log_softmax(prediction_dict['confidences'], dim=-1)\n",
    "\t\tassert torch.isfinite(log_confidences).all()\n",
    "\n",
    "\t\tbilinear = diff.unsqueeze(-2) @ precision_matrices @ diff.unsqueeze(-1)\n",
    "\t\tbilinear = bilinear[:, :, :, 0, 0]\n",
    "\t\tassert torch.isfinite(bilinear).all()\n",
    "\n",
    "\t\tlog_N = -0.5 * np.log(2 * np.pi) - 0.5 * torch.log(\n",
    "\t\t\tprediction_dict['sigma_xx'] * prediction_dict['sigma_yy']\n",
    "\t\t\t).squeeze(-1) - 0.5 * bilinear\n",
    "\t\t\t\n",
    "\t\treturn log_N, log_confidences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLLGaussian2d(Loss):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\tdef forward(self, data_dict, prediction_dict):\n",
    "\t\tlog_N, log_confidences = self._log_N_conf(data_dict, prediction_dict)\n",
    "\t\tassert torch.isfinite(log_N).all()\n",
    "\n",
    "\t\tlog_L = torch.logsumexp(log_N.sum(dim=2) + log_confidences, dim=1)\n",
    "\t\tassert torch.isfinite(log_L).all()\n",
    "\t\t\n",
    "\t\treturn -log_L.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postprocess predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limited_softplus(x):\n",
    "\treturn torch.clamp(F.softplus(x), min=0.1, max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_predictions(predicted_tensor, model_config):\n",
    "\tconfidences = predicted_tensor[:, :model_config['n_modes']]\n",
    "\tcomponents = predicted_tensor[:, model_config['n_modes']:]\n",
    "\tcomponents = components.reshape(\n",
    "\t\t-1, model_config['n_modes'], model_config['n_timestamps'], 5)\n",
    "\tsigma_xx = components[:, :, :, 2:3]\n",
    "\tsigma_yy = components[:, :, :, 3:4]\n",
    "\tvisibility = components[:, :, :, 4:]\n",
    "\treturn {\n",
    "\t\t'confidences': confidences,\n",
    "\t\t'xy': components[:, :, :, :2],\n",
    "\t\t'sigma_xx': limited_softplus(sigma_xx) if \\\n",
    "\t\t\t\tmodel_config['predict_covariances'] else torch.ones_like(sigma_xx),\n",
    "\t\t'sigma_yy': limited_softplus(sigma_yy) if \\\n",
    "\t\t\t\tmodel_config['predict_covariances'] else torch.ones_like(sigma_yy),\n",
    "\t\t'visibility': visibility\n",
    "\t}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MotionCNNDataset(Dataset):\n",
    "\tdef __init__(self, data_path, load_roadgraph=False) -> None:\n",
    "\t\tsuper().__init__()\n",
    "\t\tself._load_roadgraph = load_roadgraph\n",
    "\t\tself._files = glob(os.path.join(data_path, '*', 'agent_data', '*.npz'))\n",
    "\t\tself._roadgraph_data = glob(os.path.join(data_path, '*', 'roadgraph_data', 'segments_global.npz'))\n",
    "\t\tself._scid_to_roadgraph = {f.split('/')[-3]: f for f in self._roadgraph_data}\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self._files)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tdata = dict(np.load(self._files[idx], allow_pickle=True))\n",
    "\t\tif self._load_roadgraph:\n",
    "\t\t\troadgraph_data_file = self._scid_to_roadgraph[data['scenario_id'].item()]\n",
    "\t\t\troadgraph_data = np.load(roadgraph_data_file)['roadgraph_segments']\n",
    "\t\t\troadgraph_valid = np.ones(roadgraph_data.shape[0])\n",
    "\n",
    "\t\t\tn_to_pad = 6000 - roadgraph_data.shape[0]\n",
    "\n",
    "\t\t\troadgraph_data = np.pad(roadgraph_data, ((0, n_to_pad), (0, 0), (0, 0)))\n",
    "\t\t\troadgraph_valid = np.pad(roadgraph_valid, (0, n_to_pad))\n",
    "\n",
    "\t\t\tdata['roadgraph_data'] = roadgraph_data\n",
    "\t\t\tdata['roadgraph_valid'] = roadgraph_valid\n",
    "\t\t\t\n",
    "\t\tdata['raster'] = data['raster'].transpose(2, 0, 1) / 255.\n",
    "\t\tdata['scenario_id'] = data['scenario_id'].item()\n",
    "\t\treturn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_checkpoint_file(path):\n",
    "\tlist_of_files = glob(f'{path}/*.pth')\n",
    "\n",
    "\tif len(list_of_files) == 0:\n",
    "\t\treturn None\n",
    "\t\t\n",
    "\tlatest_file = max(list_of_files, key=os.path.getctime)\n",
    "\treturn latest_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_cuda(data_dict):\n",
    "\tgpu_required_keys = ['raster', 'future_valid', 'future_local']\n",
    "\tfor key in gpu_required_keys:\n",
    "\t\t\tdata_dict[key] = data_dict[key].cuda()\n",
    "\treturn data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_config):\n",
    "\tn_components = 5\n",
    "\tn_modes = model_config['n_modes']\n",
    "\tn_timestamps = model_config['n_timestamps']\n",
    "\toutput_dim = n_modes + n_modes * n_timestamps * n_components\n",
    "\tmodel = timm.create_model(model_config['backbone'], pretrained=True, in_chans=27, num_classes=output_dim)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(CONFIG_MODEL)\n",
    "\n",
    "optimizer = Adam(model.parameters(), **CONFIG_TRAINING['optimizer'])\n",
    "\n",
    "processed_batches = 0\n",
    "epochs_processed = 0\n",
    "\n",
    "loss_module = NLLGaussian2d()\n",
    "train_losses = []\n",
    "\n",
    "experiment_checkpoints_dir = os.path.join(PATH_CHECKPOINTS, 'basic')\n",
    "if not os.path.exists(experiment_checkpoints_dir):\n",
    "  os.makedirs(experiment_checkpoints_dir)\n",
    "\n",
    "latest_checkpoint = get_last_checkpoint_file(experiment_checkpoints_dir)\n",
    "\n",
    "if latest_checkpoint is not None:\n",
    "\tprint(f'Loading checkpoint from {latest_checkpoint}')\n",
    "\tcheckpoint_data = torch.load(latest_checkpoint)\n",
    "\n",
    "\tmodel.load_state_dict(checkpoint_data['model_state_dict'])\n",
    "\toptimizer.load_state_dict(checkpoint_data['optimizer_state_dict'])\n",
    "\tepochs_processed = checkpoint_data['epochs_processed']\n",
    "\tprocessed_batches = checkpoint_data['processed_batches']\n",
    "\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(MotionCNNDataset(PATH_PREPROCESSED_TRAINING_DATASET), **CONFIG_TRAINING['train_dataloader'])\n",
    "validation_dataloader = DataLoader(MotionCNNDataset(PATH_PREPROCESSED_VALIDATION_DATASET, load_roadgraph=True), **CONFIG_TRAINING['val_dataloader'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for epochs_processed in tqdm(\n",
    "\trange(epochs_processed, CONFIG_TRAINING['num_epochs']),\n",
    "\ttotal = CONFIG_TRAINING['num_epochs'],\n",
    "\tinitial = epochs_processed\n",
    "):\n",
    "\ttrain_progress_bar = tqdm(training_dataloader, total=len(training_dataloader))\n",
    "\n",
    "\tfor train_data in train_progress_bar:\n",
    "\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\ttrain_data = dict_to_cuda(train_data)\n",
    "\n",
    "\t\tprediction_tensor = model(train_data['raster'].float())\n",
    "\t\tprediction_dict = postprocess_predictions(prediction_tensor, model_config)\n",
    "\n",
    "\t\tloss = loss_module(train_data, prediction_dict)\n",
    "\t\tloss.backward()\n",
    "\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\ttrain_losses.append(loss.item())\n",
    "\n",
    "\t\tprocessed_batches += 1\n",
    "\t\ttrain_progress_bar.set_description(\"Train loss: %.3f\" % np.mean(train_losses[-100:]))\n",
    "\n",
    "\t\tif processed_batches % training_config['eval_every'] == 0:\n",
    "\t\t\tdel train_data\n",
    "\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tfor eval_data in tqdm(validation_dataloader):\n",
    "\t\t\t\t\teval_data = dict_to_cuda(eval_data)\n",
    "\n",
    "\t\t\t\t\tprediction_tensor = model(eval_data['raster'].float())\n",
    "\t\t\t\t\tprediction_dict = postprocess_predictions(prediction_tensor, config_model)\n",
    "\n",
    "\t\t\t\t\tloss = loss_module(eval_data, prediction_dict)\n",
    "\n",
    "\t\t\tmodel_state_dict = model.module.state_dict()\n",
    "\t\t\t\n",
    "\t\t\ttorch_checkpoint_data = {\n",
    "\t\t\t\t\"model_state_dict\": model_state_dict,\n",
    "\t\t\t\t\"optimizer_state_dict\": optimizer.state_dict(),\n",
    "\t\t\t\t\"epochs_processed\": epochs_processed,\n",
    "\t\t\t\t\"processed_batches\": processed_batches\n",
    "\t\t\t}\n",
    "\t\t\ttorch_checkpoint_path = os.path.join(experiment_checkpoints_dir, f'e{epochs_processed}_b{processed_batches}.pth')\n",
    "\t\t\ttorch.save(torch_checkpoint_data, torch_checkpoint_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
